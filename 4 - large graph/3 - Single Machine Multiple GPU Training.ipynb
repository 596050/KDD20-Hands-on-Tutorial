{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Training of GNN with Multiple GPUs\n",
    "\n",
    "In this tutorial you will learn how to train a multi-layer GraphSAGE for node classification on Amazon Copurchase Network provided by OGB with multiple GPUs.  The dataset contains 2.4 million nodes and 61 million edges, hence not able to fit in a single GPU.\n",
    "\n",
    "The contents in this tutorial include how to\n",
    "\n",
    "* Train a GNN model with a single machine with multiple GPUs on a graph of any size with `torch.nn.parallel.DistributedDataParallel`.\n",
    "\n",
    "PyTorch `DistributedDataParallel` (or DDP in short) is a common solution for multi-GPU training.  It is easy to combine DGL with PyTorch DDP, as you do the same thing as that in any ordinary PyTorch applications:\n",
    "\n",
    "* Divide the data to each GPU.\n",
    "* Distribute the model parameters using PyTorch DDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import sklearn.metrics\n",
    "import tqdm\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "The following code is copied from the first tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    import pickle\n",
    "\n",
    "    with open('data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    graph, node_features, node_labels, train_nids, valid_nids, test_nids = data\n",
    "    utils.prepare_mp(graph)\n",
    "    \n",
    "    num_features = node_features.shape[1]\n",
    "    num_classes = (node_labels.max() + 1).item()\n",
    "    \n",
    "    return graph, node_features, node_labels, train_nids, valid_nids, test_nids, num_features, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Loader for Distributed Data Parallel (DDP)\n",
    "\n",
    "In PyTorch DDP each worker process is assigned an integer *rank*.  The rank would indicate which partition of the dataset the worker process will handle.  So the only difference between single GPU and multiple GPU training in terms of data loader is that the data loader will only iterate over a partition of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(rank, world_size, graph, nids):\n",
    "    partition_size = len(nids) // world_size\n",
    "    partition_offset = partition_size * rank\n",
    "    nids = nids[partition_offset:partition_offset+partition_size]\n",
    "    \n",
    "    sampler = dgl.dataloading.MultiLayerNeighborSampler([4, 4, 4])\n",
    "    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "        graph, nids, sampler,\n",
    "        batch_size=1024,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model\n",
    "\n",
    "The model implementation will be exactly the same as what you have seen in the first tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, n_layers):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats, n_hidden, 'mean'))\n",
    "        for i in range(1, n_layers - 1):\n",
    "            self.layers.append(dglnn.SAGEConv(n_hidden, n_hidden, 'mean'))\n",
    "        self.layers.append(dglnn.SAGEConv(n_hidden, n_classes, 'mean'))\n",
    "        \n",
    "    def forward(self, blocks, x):\n",
    "        for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
    "            x = layer(block, x)\n",
    "            if l != self.n_layers - 1:\n",
    "                x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributing the Model to GPUs\n",
    "\n",
    "PyTorch DDP manages the distribution of models and synchronization of the gradients for you.  In DGL, you can benefit from PyTorch DDP as well by simply wrapping the model with `torch.nn.parallel.DistributedDataParallel`.\n",
    "\n",
    "The recommended way to distribute training is to have one training process per GPU, so during model instantiation we also specify the process rank, which is equal to the GPU ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(rank, in_feats, n_hidden, n_classes, n_layers):\n",
    "    model = SAGE(in_feats, n_hidden, n_classes, n_layers).to(rank)\n",
    "    return DistributedDataParallel(model, device_ids=[rank], output_device=rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Training Loop for one Process\n",
    "\n",
    "The training loop looks the same as other PyTorch DDP applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.fix_openmp\n",
    "def train(rank, world_size, data):\n",
    "    # data is the output of load_data\n",
    "    torch.distributed.init_process_group(\n",
    "        backend='nccl',\n",
    "        init_method='tcp://127.0.0.1:12345',\n",
    "        world_size=world_size,\n",
    "        rank=rank)\n",
    "    torch.cuda.set_device(rank)\n",
    "    \n",
    "    graph, node_features, node_labels, train_nids, valid_nids, test_nids, num_features, num_classes = data\n",
    "    \n",
    "    train_dataloader = create_dataloader(rank, world_size, graph, train_nids)\n",
    "    # We only use one worker for validation\n",
    "    valid_dataloader = create_dataloader(0, 1, graph, valid_nids)\n",
    "    \n",
    "    model = init_model(rank, num_features, 128, num_classes, 3)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    torch.distributed.barrier()\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model_path = 'model.pt'\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "\n",
    "        for step, (input_nodes, output_nodes, blocks) in enumerate(train_dataloader):\n",
    "            inputs = node_features[input_nodes].cuda()\n",
    "            labels = node_labels[output_nodes].cuda()\n",
    "            predictions = model(blocks, inputs)\n",
    "\n",
    "            loss = F.cross_entropy(predictions, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            accuracy = sklearn.metrics.accuracy_score(labels.cpu().numpy(), predictions.argmax(1).detach().cpu().numpy())\n",
    "\n",
    "            if rank == 0 and step % 10 == 0:\n",
    "                print('Epoch {:05d} Step {:05d} Loss {:.04f}'.format(epoch, step, loss.item()))\n",
    "\n",
    "        torch.distributed.barrier()\n",
    "        \n",
    "        if rank == 0:\n",
    "            model.eval()\n",
    "            predictions = []\n",
    "            labels = []\n",
    "            with tqdm.tqdm_notebook(valid_dataloader) as tq, torch.no_grad():\n",
    "                for input_nodes, output_nodes, blocks in tq:\n",
    "                    inputs = node_features[input_nodes].cuda()\n",
    "                    labels.append(node_labels[output_nodes].numpy())\n",
    "                    predictions.append(model.module(blocks, inputs).argmax(1).cpu().numpy())\n",
    "                predictions = np.concatenate(predictions)\n",
    "                labels = np.concatenate(labels)\n",
    "                accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "                print('Epoch {} Validation Accuracy {}'.format(epoch, accuracy))\n",
    "                if best_accuracy < accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    torch.save(model.module.state_dict(), best_model_path)\n",
    "                    \n",
    "        torch.distributed.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coo', 'csr', 'csc']\n",
      "Epoch 00000 Step 00000 Loss 6.8194\n",
      "Epoch 00000 Step 00010 Loss 2.7267\n",
      "Epoch 00000 Step 00020 Loss 2.2743\n",
      "Epoch 00000 Step 00030 Loss 1.8698\n",
      "Epoch 00000 Step 00040 Loss 1.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87c70619a0147f8b32f42963366c664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 Validation Accuracy 0.7069145283930525\n",
      "Epoch 00001 Step 00000 Loss 1.5336\n",
      "Epoch 00001 Step 00010 Loss 1.3781\n",
      "Epoch 00001 Step 00020 Loss 1.3528\n",
      "Epoch 00001 Step 00030 Loss 1.3083\n",
      "Epoch 00001 Step 00040 Loss 1.2994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c0153dc49a4e1eb962163518fd2446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Validation Accuracy 0.791190906085497\n",
      "Epoch 00002 Step 00000 Loss 1.1379\n",
      "Epoch 00002 Step 00010 Loss 1.0715\n",
      "Epoch 00002 Step 00020 Loss 1.0465\n",
      "Epoch 00002 Step 00030 Loss 1.0820\n",
      "Epoch 00002 Step 00040 Loss 0.9921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebf21f36d99481db1e6b7d2e51e1478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Validation Accuracy 0.8177911146148564\n",
      "Epoch 00003 Step 00000 Loss 1.0641\n",
      "Epoch 00003 Step 00010 Loss 1.0089\n",
      "Epoch 00003 Step 00020 Loss 0.9286\n",
      "Epoch 00003 Step 00030 Loss 0.9309\n",
      "Epoch 00003 Step 00040 Loss 1.0498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800ba5eae70448389010e06af3f0533c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Validation Accuracy 0.8342954504997075\n",
      "Epoch 00004 Step 00000 Loss 1.0211\n",
      "Epoch 00004 Step 00010 Loss 0.9226\n",
      "Epoch 00004 Step 00020 Loss 0.8738\n",
      "Epoch 00004 Step 00030 Loss 0.8745\n",
      "Epoch 00004 Step 00040 Loss 0.9150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39051eb8ba2d4566a7cb3d04a5e1e5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Validation Accuracy 0.844365892734532\n",
      "Epoch 00005 Step 00000 Loss 0.8598\n",
      "Epoch 00005 Step 00010 Loss 0.8585\n",
      "Epoch 00005 Step 00020 Loss 0.8589\n",
      "Epoch 00005 Step 00030 Loss 0.7234\n",
      "Epoch 00005 Step 00040 Loss 0.8061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e5155ea0fa461eb16ac7655503caa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Validation Accuracy 0.8473412506675483\n",
      "Epoch 00006 Step 00000 Loss 0.8904\n",
      "Epoch 00006 Step 00010 Loss 0.7703\n",
      "Epoch 00006 Step 00020 Loss 0.8840\n",
      "Epoch 00006 Step 00030 Loss 0.8748\n",
      "Epoch 00006 Step 00040 Loss 0.8140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36d4d911b2b4dbeafcd4a64020eb3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Validation Accuracy 0.8504437606489841\n",
      "Epoch 00007 Step 00000 Loss 0.7839\n",
      "Epoch 00007 Step 00010 Loss 0.8774\n",
      "Epoch 00007 Step 00020 Loss 0.7986\n",
      "Epoch 00007 Step 00030 Loss 0.7188\n",
      "Epoch 00007 Step 00040 Loss 0.8071\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e431f48f044ae0a9be4bf2e3d0d29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Validation Accuracy 0.851206672939501\n",
      "Epoch 00008 Step 00000 Loss 0.7798\n",
      "Epoch 00008 Step 00010 Loss 0.7694\n",
      "Epoch 00008 Step 00020 Loss 0.7875\n",
      "Epoch 00008 Step 00030 Loss 0.7783\n",
      "Epoch 00008 Step 00040 Loss 0.6415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a586d9818deb477090d58c51fa5b4f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Validation Accuracy 0.8576659969992116\n",
      "Epoch 00009 Step 00000 Loss 0.7488\n",
      "Epoch 00009 Step 00010 Loss 0.7146\n",
      "Epoch 00009 Step 00020 Loss 0.7745\n",
      "Epoch 00009 Step 00030 Loss 0.7785\n",
      "Epoch 00009 Step 00040 Loss 0.7097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6104aaf6f90b40a0b520b332a6f18bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Validation Accuracy 0.859624138544872\n",
      "Epoch 00010 Step 00000 Loss 0.7197\n",
      "Epoch 00010 Step 00010 Loss 0.8006\n",
      "Epoch 00010 Step 00020 Loss 0.6581\n",
      "Epoch 00010 Step 00030 Loss 0.7120\n",
      "Epoch 00010 Step 00040 Loss 0.7275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d1405c45b8430f88ef7b68f54fc50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Validation Accuracy 0.8615822800905323\n",
      "Epoch 00011 Step 00000 Loss 0.7184\n",
      "Epoch 00011 Step 00010 Loss 0.7176\n",
      "Epoch 00011 Step 00020 Loss 0.6674\n",
      "Epoch 00011 Step 00030 Loss 0.6842\n",
      "Epoch 00011 Step 00040 Loss 0.6612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d539b8e847b54836a90b97723aa90e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Validation Accuracy 0.86267578770694\n",
      "Epoch 00012 Step 00000 Loss 0.7541\n",
      "Epoch 00012 Step 00010 Loss 0.7052\n",
      "Epoch 00012 Step 00020 Loss 0.6887\n",
      "Epoch 00012 Step 00030 Loss 0.6068\n",
      "Epoch 00012 Step 00040 Loss 0.6764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be347f452a434653a02e445fafb20b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 Validation Accuracy 0.8621671795132619\n",
      "Epoch 00013 Step 00000 Loss 0.7154\n",
      "Epoch 00013 Step 00010 Loss 0.7305\n",
      "Epoch 00013 Step 00020 Loss 0.6302\n",
      "Epoch 00013 Step 00030 Loss 0.6839\n",
      "Epoch 00013 Step 00040 Loss 0.6643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6573b6430a674cca91975549e6a7923a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 Validation Accuracy 0.8561147420084938\n",
      "Epoch 00014 Step 00000 Loss 0.6759\n",
      "Epoch 00014 Step 00010 Loss 0.7228\n",
      "Epoch 00014 Step 00020 Loss 0.7989\n",
      "Epoch 00014 Step 00030 Loss 0.7027\n",
      "Epoch 00014 Step 00040 Loss 0.7883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a310320c8dca48589e2249fb345f47ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 Validation Accuracy 0.8631843959006179\n",
      "Epoch 00015 Step 00000 Loss 0.6412\n",
      "Epoch 00015 Step 00010 Loss 0.6829\n",
      "Epoch 00015 Step 00020 Loss 0.6613\n",
      "Epoch 00015 Step 00030 Loss 0.6583\n",
      "Epoch 00015 Step 00040 Loss 0.6196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed09dfbcb3c4fdf91a332fda50630b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 Validation Accuracy 0.8673804134984615\n",
      "Epoch 00016 Step 00000 Loss 0.6129\n",
      "Epoch 00016 Step 00010 Loss 0.6114\n",
      "Epoch 00016 Step 00020 Loss 0.6273\n",
      "Epoch 00016 Step 00030 Loss 0.6406\n",
      "Epoch 00016 Step 00040 Loss 0.5958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba38c7418cc64417a16157149989cad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 Validation Accuracy 0.8676855784146683\n",
      "Epoch 00017 Step 00000 Loss 0.6194\n",
      "Epoch 00017 Step 00010 Loss 0.6134\n",
      "Epoch 00017 Step 00020 Loss 0.6693\n",
      "Epoch 00017 Step 00030 Loss 0.6642\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    procs = []\n",
    "    data = load_data()\n",
    "    for proc_id in range(4):    # 4 gpus\n",
    "        p = mp.Process(target=train, args=(proc_id, 4, data))\n",
    "        p.start()\n",
    "        procs.append(p)\n",
    "    for p in procs:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you have learned how to train a multi-layer GraphSAGE for node classification on a large dataset that cannot fit into GPU.  The method you have learned can scale to a graph of any size, and works on a single machine with *any number of* GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
